## 1.1 引入

- 人工智能：能够感知、推理、行动和适应的程序
- 机器学习：能够随着数据量的增加不断改进性能的算法
- 深度学习：机器学习的一个子集，利用多层神经网络从大量数据中进行学习

### 1.1.1 定义

经典定义：利用经验改善系统自身的性能.

<img src="https://raw.githubusercontent.com/AnJian2020/study_recorder/main/images/202308212325948.png" alt="image-20230821232520705" style="zoom:50%;" />

<img src="https://raw.githubusercontent.com/AnJian2020/study_recorder/main/images/202308212325524.png" alt="image-20230821232552423" style="zoom:50%;" />

机器学习的作用：搜索引擎检索、竞选结果预测、棋类人机大战、汽车自动驾驶、淘宝推荐、交通预测。

> 机器学习成功应用的三个重要条件：
>
> 1. 大数据
> 2. 强大的计算能力
> 3. 算法上的突破

机器学习是一门从数据中研究算法的多领域交叉学科，研究计算机如何模拟或实现人类的学习行为，根据已有的数据或以往的经验进行算法选择、构建模型，预测新数据，并重新组织已有的知识结构使之不断改进自身的性能。

<img src="https://raw.githubusercontent.com/AnJian2020/study_recorder/main/images/202308212330191.png" alt="image-20230821233016057" style="zoom:50%;" />

### 1.1.2 机器如何学习

<img src="https://raw.githubusercontent.com/AnJian2020/study_recorder/main/images/202308212331631.png" alt="image-20230821233132418" style="zoom:50%;" />

**数据预处理（数据清洗、数据采样）=> 特征工程（特征选择）=>数据建模（回归问题、分类问题、聚类问题）=>结果评估（拟合度量、查准率、查全率）**

1. 数据预处理

   - 数据采样。数据不平衡，指数据集的类别发布不均。解决方法：**过采样**（Over-Sampling），即通过随机复制少数类来增加其中的实例数量，从而可增加样本中少数类的代表性；**欠采样**（Under-Sampling），即通过随机地消除占多数的类的样本来平衡类分布，直到多数类和少数类的实例实现平衡。

   - 数据清洗。对各种脏数据进行对应方式的处理，得到标准、干净、连续的数据，提供给数据统计、数据挖掘等使用。

     数据的完整性，例如人的属性中缺少性别、籍贯、年龄等，解决方法是**信息补全**（使用身份证件号码推算性别、籍贯、出生日期、年龄等）或者剔除。

     数据的合法性，例如获取数据与常识不符，年龄大于150岁，解决方法是**设置字段内容**（日期字段格式为 “2010-10-10”）；**类型的合法规则**（性别 in [男、 女、未知]）。

     数据的一致性，例如不同来源的不同指标，实际内涵是一样的，或是同一指标内涵不一致，解决方法是**建立数据体系**，包含但不限于指标体系、维度、单位、频度等。

2. 特征工程

   特征工程是指在机器学习和数据挖掘任务中，通过对原始数据进行变换、提取和选择，创建能够更好地表示问题的特征集合的过程，包含了数据清洗、特征选择、特征变换、特征构建、特征降维，目标是从原始数据中提取出最具有代表性和信息量的特征，以便更好地描述问题和训练机器学习模型。

3. 数据建模

   监督学习：分类问题和回归问题。无监督学习：聚类问题。其他：强化学习、深度学习、隐马尔可夫模型等。

   - 分类问题：主要解决如何利用模型来判别一个数据点的类别。这个类别一般是离散的，比如两类或者多类。可利用的模型有决策树、贝叶斯、支持向量机、逻辑回归和集成学习等。
   - 回归问题：主要是利用模型来输出一个预测的数值。这个数值一般是一个实数，是连续的。可利用的模型有线性回归、岭回归、Lasso回归等。
   - 聚类问题：没有明显的目标或响应变量，往往是希望发现数据内部潜在的结构和规律，为进一步决断提供参考。常用的聚类模型有划分聚类的典型代表K-Means算法、高斯混合聚类、密度聚类、层次聚类、谱聚类。
   - 其他问题：隐马尔可夫模型、LDA主题模型、条件随机场、神经网络、深度学习。

4. 结果评估

   <img src="https://raw.githubusercontent.com/AnJian2020/study_recorder/main/images/202308212358897.png" alt="image-20230821235813769" style="zoom:50%;" />

   - 性能评价指标-分类。

     **准确率**(Accuracy)是指在分类中，分类正确的记录个数占总记录个数的比。
     $$
     accuracy = \frac{n_{correct}}{n_{total}}
     $$

### 1.1.3 典型的机器学习过程

<img src="https://raw.githubusercontent.com/AnJian2020/study_recorder/main/images/202308220003869.png" alt="image-20230822000301704" style="zoom:50%;" />

## 1.2 基础知识

属性组成的空间成为属性空间、输入空间或样本空间。

假设空间是由输入空间到输出空间的映射构成的集合，每个映射对应一个模型，假设空间确定了模型预测的范围。简单的说，由模型输出的所有可能取值构成的空间，为假设空间。

所有标记的集合，称为“标记空间label space，或”输出空间“

<img src="https://raw.githubusercontent.com/AnJian2020/study_recorder/main/images/202308221719358.png" alt="image-20230822171943165" style="zoom:50%;" />

学得模型适用于新样本的能力，称为泛化能力。

通常假设样本空间中全体样本服从一个未知分布，我们获得的每个样本都是独立地从这个分布上采样获得的，即“独立同分布”。一般而言，训练样本越多，我们获得关于这个分布的信息越多，这样就越有可能通过学习获得具有强泛化能力的模型。

学习过程 ： 在所有假设(hypothesis)组成的空间中进行搜索的过程

目标：找到与训练集“匹配”(fit)的假设

> **奥卡姆剃刀原则**：若有多个假设与观察一致，则选择最简单的那个。 A曲线更平滑，意味着更简单，A更易于描述，选择A

![image-20230822172235684](https://raw.githubusercontent.com/AnJian2020/study_recorder/main/images/202308221722759.png)

NFL定理的重要前提：所有“问题”出现的机会相同、或所有问题同等重要

**均值**

样本集合的平均值，是表示一组数据**集中趋势**的量数，反映一组数据的一般情况、平均水平，也可以用它进行不同组数据的比较，以看出组与组之间的差别。
$$
\overline{x} = {{\sum_{i=1}^nx_i}\over{n}}
$$

> **学习能力不行造成的误差是偏差，学习能力太强造成的误差是方差。**

对于RF，我们实际上是部分实现了多次训练取均值的效果，每次训练得到的树都是一个很强的学习者，每一个的方差都比较大，但综合起来就会比较小。好比一个很强的学习者学习时，刮着西风，它会据此调整自己的瞄准方法，另一个很强的学习者学习时刮着东风，（西风、东风可以理解为不同训练集中的噪声）它也会据此调整自己的瞄准方法，在测试样本时，一个误差向西，一个误差向东，刚好起到互相抵消的作用，所以方差会比较小。但是由于每棵树的偏差都差不多，所以，我们取平均时，偏差不会怎么变化。
