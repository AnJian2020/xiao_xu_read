## 2.1 引言

在机器学习方法中，回归分析是一种预测性的建模技术，它研究因变量（目标特征）和自变量（特征）之间的关系。这种技术通常用于预测分析、时间序列模型以及发现特征之间的因果关系。

## 2.2 一元线性回归

一元线性回归模型：y=ax+b，x为自变量，y为因变量，a为系数是斜率，b是截距。

> 线性回归，就是能够用一条直线较为精确地描述数据之间的关系 。

不同的a和b，可做出不同的线，找出更能完美体现x和y对应关系的线的过程，就是确定模型参数的过程。

![image-20230822223051657](https://raw.githubusercontent.com/AnJian2020/study_recorder/main/images/202308222230750.png)

重写y=ax+b为h=θ_0+θ_1x，简化问题，减少参数的数量=> h = θ*x

**MSE**：均方误差（误差平方和的均值）
$$
J = {1\over{m}}{\sum_{i=0}^{m-1}(h_i-y_i)^2}
$$
误差平方和的均值用一个符号J表示，J值为m个样本的误差平方和的均值，**hi**为第i个样本的预测值，**yi**为第i个样本的真实值。

J我们称为代价函数/误差函数。

![image-20230822223754668](https://raw.githubusercontent.com/AnJian2020/study_recorder/main/images/202308222237737.png)

- 当θ值在θ最优的右侧时，能够不停的向左迭代，靠近θ最优。
- 当θ值在θ最优的左侧时，能够不停的向右迭代，靠近θ最优。

![image-20230822223908962](https://raw.githubusercontent.com/AnJian2020/study_recorder/main/images/202308222239022.png)

相关系数是用以反映变量之间相关关系密切程度的统计指标。
$$
r(相关系数)={cov(x,y)\over{σ_x*σ_y}}
$$
对于相关性强度r来说有以下的关系：

- 0~0.3 弱相关
- 0.3~0.6 中等程度相关
- 0.6~1 强相关

均方误差 =  Σ(y实际值 - y预测值)^2 /样本数

方差 = Σ(y实际值 - y平均值)^2，表示y的总波动

Score：决定系数R平方= 1 – SSE/方差 

- 回归线拟合程度：有多少百分比的y波动被回归线来描述(x的波动变化)
- 值大小：R平方越高，回归模型越精确(取值范围0~1)，1无误差，0无法完成拟合，对于预测来说我们需要运用函数中的model.predict()来得到预测值.
